# Website Information Retrieval and Question Answering System

![image](https://github.com/user-attachments/assets/90c4e679-e223-4012-8aa2-f467b465ed06)

This project is a web-based application powered by Streamlit and LangChain that enables users to extract information from any website by providing its link. Users can then ask questions about the content of the website, and the system will provide relevant answers using OpenAI's GPT model. This repository includes the front-end (`d1.py`) and back-end logic (`demo.py`) for the system.

---

## Features

### **1. User Interaction Layer**
- **User Input Options:**
  - Users can input the name and link of a website to extract its content.
  - Ask any question related to the content of the uploaded website.
- **Dynamic Content Loading:**
  - The system loads and splits the content of the specified website into smaller chunks for efficient processing.
- **Interactive Interface:**
  - Users can interact with the application to get answers to their queries.

### **2. Application Frontend (Streamlit)**
- **Home Page:**
  - Allows users to input the website name and link.
  - Sets up the retriever for querying the content of the website.
- **Display Page:**
  - Users can ask questions about the content of the uploaded website.
  - Displays answers generated by OpenAI GPT.

### **3. Core Processing Layer**
- **LangChain:**
  - Processes the content of the website using LangChain's utilities for document loading, splitting, and vector storage.
- **FAISS Vector Store:**
  - Creates an optimized vector database for efficient information retrieval.
- **OpenAI GPT (LLM):**
  - Processes user queries and generates relevant responses by interacting with the retriever.

### **4. Tool Integration Layer**
- **Custom Retriever Tool:**
  - Configures a retriever tool specific to the website content provided by the user.
- **LangChain Agents:**
  - Manages the interaction between the OpenAI GPT model and the retriever.

### **5. Data Flow**
1. User inputs a website name and link via the Home page.
2. The system extracts and processes the content of the website.
3. Users navigate to the Display page to ask questions about the content.
4. The system retrieves the relevant information and generates an answer.

---

## Key Features Highlighted
- **Modularity:** The application allows integration with any website link, enabling dynamic content processing.
- **Ease of Use:** Interactive Streamlit interface ensures a user-friendly experience.
- **Scalability:** Designed to support additional functionality, such as integrating more complex question-answering capabilities or handling multiple links.

---

## Installation

### Prerequisites
- Python 3.8 or higher
- [pip](https://pip.pypa.io/en/stable/)

### Clone the Repository
```bash
git clone https://github.com/your-username/website-info-retrieval.git
cd website-info-retrieval
```

### Install Dependencies
Install the required Python libraries:
```bash
pip install -r requirements.txt
```

---

## Configuration

### Set up Environment Variables
Create a `.env` file in the root directory and add your OpenAI API key:
```
OPENAI_API_KEY=your_openai_api_key
```

---

## How to Run

1. Run the front-end application:
   ```bash
   streamlit run d1.py
   ```
2. The application will launch in your default browser. Use the "Home" page to set up a website, and the "Display" page to interact with the content.

For additional back-end testing or development, run:
```bash
python demo.py
```

---

## Project Structure

```
website-info-retrieval/
â”œâ”€â”€ d1.py                # Frontend for the application
â”œâ”€â”€ demo.py              # Backend logic for testing and retrieving data
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ .env                 # Environment file for API keys
â”œâ”€â”€ README.md            # Project documentation
```

---

## Requirements

### `requirements.txt`
```plaintext
streamlit
langchain
langchain-community
openai
faiss-cpu
python-dotenv
```

---

## Future Enhancements

1. **Multi-Link Support:** Allow users to upload and query multiple websites simultaneously.
2. **Enhanced UI:** Improve the front-end design for a more seamless user experience.
3. **PDF and Document Integration:** Enable querying of uploaded PDFs or documents in addition to web content.
4. **Real-Time Updates:** Add support for dynamic content scraping with auto-refresh.
5. **Deployment:** Deploy the application for real-world use.

---

## License
[MIT License](LICENSE)

---

Feel free to contribute or raise issues for further improvements! ðŸŽ‰
